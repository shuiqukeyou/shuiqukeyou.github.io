<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="Z5SXAd9_vgtfS3nzsDbs8LBIhQ_RbxIvgYOJwJL5slI">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://shuiqu.moe').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="graphSAGE的论文，折腾GCN的人必读一篇论文。GCN计算需要完整图结构，既消耗硬件资源、也没法进行mini-batch学习。 本论文提出了graphSAGE模型，其核心思想是，通过对学习过程进行采样，近似完成GCN的计算过程，从而可以分批采样以达到进行batch学习的目的。另外对于图中新增的节点，只需要对新添加的节点进行采样学习即可。 （这篇论文在2020年1月左右阅读）">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读：Inductive Representation Learning on Large Graphs">
<meta property="og:url" content="https://shuiqu.moe/2020/09/29/graphsage-paper/index.html">
<meta property="og:site_name" content="ShuiQU">
<meta property="og:description" content="graphSAGE的论文，折腾GCN的人必读一篇论文。GCN计算需要完整图结构，既消耗硬件资源、也没法进行mini-batch学习。 本论文提出了graphSAGE模型，其核心思想是，通过对学习过程进行采样，近似完成GCN的计算过程，从而可以分批采样以达到进行batch学习的目的。另外对于图中新增的节点，只需要对新添加的节点进行采样学习即可。 （这篇论文在2020年1月左右阅读）">
<meta property="og:image" content="https://shuiqu.moe/2020/09/29/graphsage-paper/image-20200929165433571.png">
<meta property="og:image" content="https://shuiqu.moe/2020/09/29/graphsage-paper/equation1.svg">
<meta property="og:image" content="https://shuiqu.moe/2020/09/29/graphsage-paper/equation2.svg">
<meta property="og:image" content="https://shuiqu.moe/2020/09/29/graphsage-paper/equation3.svg">
<meta property="og:image" content="https://shuiqu.moe/2020/09/29/graphsage-paper/image-20200928162125409.png">
<meta property="article:published_time" content="2020-09-29T08:58:58.000Z">
<meta property="article:modified_time" content="2020-10-04T08:42:56.358Z">
<meta property="article:author" content="ShuiQu">
<meta property="article:tag" content="GCN">
<meta property="article:tag" content="graphSAGE">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://shuiqu.moe/2020/09/29/graphsage-paper/image-20200929165433571.png">

<link rel="canonical" href="https://shuiqu.moe/2020/09/29/graphsage-paper/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>论文阅读：Inductive Representation Learning on Large Graphs | ShuiQU</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>


    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ShuiQU</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">Save you from anything</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-tasks"></i>分类</a>

  </li>
        <li class="menu-item menu-item-归档">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://shuiqu.moe/2020/09/29/graphsage-paper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ShuiQu">
      <meta itemprop="description" content="一直摸鱼一直爽">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ShuiQU">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          论文阅读：Inductive Representation Learning on Large Graphs
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-29 16:58:58" itemprop="dateCreated datePublished" datetime="2020-09-29T16:58:58+08:00">2020-09-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-04 16:42:56" itemprop="dateModified" datetime="2020-10-04T16:42:56+08:00">2020-10-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>
            </span>

          
            <span id="/2020/09/29/graphsage-paper/" class="post-meta-item leancloud_visitors" data-flag-title="论文阅读：Inductive Representation Learning on Large Graphs" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/09/29/graphsage-paper/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/09/29/graphsage-paper/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>graphSAGE的论文，折腾GCN的人必读一篇论文。GCN计算需要完整图结构，既消耗硬件资源、也没法进行mini-batch学习。</p>
<p>本论文提出了graphSAGE模型，其核心思想是，通过对学习过程进行采样，近似完成GCN的计算过程，从而可以分批采样以达到进行batch学习的目的。另外对于图中新增的节点，只需要对新添加的节点进行采样学习即可。</p>
<p>（这篇论文在2020年1月左右阅读）</p>
<a id="more"></a>

<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>GCN的一个问题在于，每次学习都需要将整个图送入显存/内存中，资源消耗巨大。另外使用整个图结构进行学习，导致了GCN的学习的固化，图中一旦新增节点，整个图的学习都需要重新进行。这两点对于大数据集和项目实际落地来说，是巨大的阻碍。</p>
<h2 id="graphSAGE的原理"><a href="#graphSAGE的原理" class="headerlink" title="graphSAGE的原理"></a>graphSAGE的原理</h2><p>和GCN的论文一样，本咸鱼选择跳过论文中的数学证明，网上有大把比我分析的好的文章，想看数学原理建议阅读论文本体或者去看其他大手子们的文章。我这里只写一些个人理解。</p>
<h3 id="GCN的计算细节"><a href="#GCN的计算细节" class="headerlink" title="GCN的计算细节"></a>GCN的计算细节</h3><p>了解了GCN的工作模式之后会发现一个事实，每轮卷积中，每个节点只和自己周围的节点交换信息。如果是单层GCN，那么每个节点只能接受到自己一跳内邻居的信息。两层的话则是两跳（通过一跳邻居间接传播过来），如图所示：</p>
<img src="/2020/09/29/graphsage-paper/image-20200929165433571.png" class="">

<p>假设我只需要图中一个点的卷积的结果，并且只使用了一层GCN，那么实际上我只需要这个节点和它的全部邻居节点，图中的其他节点是没有意义的；</p>
<p>如果使用了两层GCN，那么我只需要这个节点和它的两跳以内的全部邻居，以此类推。因为更远节点的信息根本无法到达这个节点。</p>
<p>如此，便可以实现GCN的mini-batch，一次取出一组待训练节点和它们训练所需的N跳内的邻居节点即可，因为这些节点的训练本来也不需要更远的节点的信息。</p>
<h3 id="通过采样进行近似"><a href="#通过采样进行近似" class="headerlink" title="通过采样进行近似"></a>通过采样进行近似</h3><p>用过抽取出一部分待训练节点和它们的N跳内邻居可以完成这些节点的训练。但并不是说只进行这种操作就可以完成顺利mini-batch训练。例如，图中的某些节点是有几百上千个邻居的超级节点，对于这种节点，哪怕只进行一跳邻居采样，仍然会导致计算困难。</p>
<p>针对这个问题，本论文提出了采样的思路，即，只对目标节点的邻居进行一定数量的采样，然后通过这次被采样出来的节点和目标节点进行计算，从而逼近完全聚合的效果。</p>
<h2 id="graphSAGE的具体实现"><a href="#graphSAGE的具体实现" class="headerlink" title="graphSAGE的具体实现"></a>graphSAGE的具体实现</h2><p>有了上述的分析，我们便清楚了graphSAGE的思路是，通过采样实现对整个图进行分批和近似计算。那么就有两个问题需要解决：<strong>如何进行采样</strong>以及<strong>如何进行计算</strong>。</p>
<h3 id="采样的实现"><a href="#采样的实现" class="headerlink" title="采样的实现"></a>采样的实现</h3><p>作者没有在采样上折腾出花来，而是直接选择了随机采样。原版代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UniformNeighborSampler</span><span class="params">(Layer)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Uniformly samples neighbors.</span></span><br><span class="line"><span class="string">    Assumes that adj lists are padded with random re-sampling</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, adj_info, **kwargs)</span>:</span></span><br><span class="line">        super(UniformNeighborSampler, self).__init__(**kwargs)</span><br><span class="line">        self.adj_info = adj_info</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        ids, num_samples = inputs</span><br><span class="line">        adj_lists = tf.nn.embedding_lookup(self.adj_info, ids) </span><br><span class="line">        adj_lists = tf.transpose(tf.random_shuffle(tf.transpose(adj_lists)))</span><br><span class="line">        adj_lists = tf.slice(adj_lists, [<span class="number">0</span>,<span class="number">0</span>], [<span class="number">-1</span>, num_samples])</span><br><span class="line">        <span class="keyword">return</span> adj_lists</span><br></pre></td></tr></table></figure>

<p>可以看到是根据num_samples指定的数量，对<strong>邻居</strong>进行随机采样。</p>
<p>因为没有什么证据表明，邻居节点的分布遵循某个分布，所以普通的随机采样反而效果较稳定（另外作者可能试过按常见分布的采样方法，改几行代码的事），论文中有关于使用随机采样论证。</p>
<p>前面已经提过，由于GCN的特性：一层GCN中，节点只直接和邻居节点发生信息交换。所以叠加了几层GCN，就应该采样几跳内的邻居节点。</p>
<h3 id="聚合特征的方法"><a href="#聚合特征的方法" class="headerlink" title="聚合特征的方法"></a>聚合特征的方法</h3><p>采样完成后，等于是从原图中抽取出来了一个子图。对于这个batch的计算全部在这个子图上完成。</p>
<p>本论文并不是只实现了一个采样，然后计算部分全部照搬GCN（我导师管这种情况叫创新性不够）。而是自己提出了几个聚合信息的方法：</p>
<ul>
<li>均值聚合：普通均值聚合、基于修正的均值聚合</li>
<li>LSTM聚合</li>
<li>池化聚合：均值池化、最大值池化</li>
</ul>
<p>其中普通均值聚合是简单的将邻居节点取均值，然后和待运算节点连接后，进行一次矩阵变换。</p>
<img src="/2020/09/29/graphsage-paper/equation1.svg" class="">

<p>而基于修正的均值聚合的计算公式如下。</p>
<img src="/2020/09/29/graphsage-paper/equation2.svg" class="">

<p>这个算法在聚合邻居节点的特征时就已经有了一定的权重，近似模拟GCN的计算过程。</p>
<p>而LSTM聚合是将邻居节点逐个输入LSTM中，因为作者认为LSTM(RNNs)比均值聚合有着更强的特征提取能力。但LSTM是适合于编码顺序数据的，因此每次使用LSTM聚合计算时需要进行一次随机打乱。</p>
<p>而池化聚合是考虑到了GCN的特性，GCN本身就是在平滑同类节点的嵌入结果，而使用均值或最大值池化，更有利于提取同类节点的特征。计算公式如下：</p>
<img src="/2020/09/29/graphsage-paper/equation3.svg" class="">

<p>（作者声称，实验结果显示，均值池化和最大值池化没有显著的性能差距，故他们将重点放在了最大值池化上）</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>通常我是不提及实验结果的，因为反正结果做的差也不会发上来。不过这篇论文的结果不是一水的往一个方向倒。所以我把实验结果弄上来。</p>
<p>本论文使用了三个数据集：</p>
<ul>
<li>Web of Science引文数据集。目标是将学术论文分类为不同的主题</li>
<li>Reddit帖子。目标是将发帖人归为不同社区的成员</li>
<li>各种生物学蛋白质的功能分类蛋白质-蛋白质相互作用（PPI）图。目标是对未知的PPI图进行概括</li>
</ul>
<p>实验结果如下：</p>
<img src="/2020/09/29/graphsage-paper/image-20200928162125409.png" class="">

<p>我想说的是：graphSAGE并没有duang的就在三个数据集上都表现出某一个聚合方法比较好。四个方法各有千秋，如果要用graphSAGE建议都试试。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇论文也是2017年的了，后面又有一些其他七七八八的针对graph进行采样从而实现mini-batch的算法，某些方面比这篇文章更好，不过这篇文章仍然是GCN项目落地的必读文章之一。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/GCN/" rel="tag"># GCN</a>
              <a href="/tags/graphSAGE/" rel="tag"># graphSAGE</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/09/29/%E5%9F%BA%E4%BA%8ELDA%E5%92%8Ctfidf%E7%9A%84%E6%96%87%E6%A1%A3%E5%9B%BE%E7%9A%84%E5%AD%90%E5%9B%BE%E6%B5%8B%E8%AF%95/" rel="prev" title="基于LDA和tfidf的文档图的子图测试">
      <i class="fa fa-chevron-left"></i> 基于LDA和tfidf的文档图的子图测试
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/10/04/text-gcn-paper/" rel="next" title="论文阅读：Graph Convolutional Networks for Text Classification">
      论文阅读：Graph Convolutional Networks for Text Classification <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#研究背景"><span class="nav-number">1.</span> <span class="nav-text">研究背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#graphSAGE的原理"><span class="nav-number">2.</span> <span class="nav-text">graphSAGE的原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GCN的计算细节"><span class="nav-number">2.1.</span> <span class="nav-text">GCN的计算细节</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#通过采样进行近似"><span class="nav-number">2.2.</span> <span class="nav-text">通过采样进行近似</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#graphSAGE的具体实现"><span class="nav-number">3.</span> <span class="nav-text">graphSAGE的具体实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#采样的实现"><span class="nav-number">3.1.</span> <span class="nav-text">采样的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#聚合特征的方法"><span class="nav-number">3.2.</span> <span class="nav-text">聚合特征的方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实验结果"><span class="nav-number">4.</span> <span class="nav-text">实验结果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ShuiQu</p>
  <div class="site-description" itemprop="description">一直摸鱼一直爽</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ShuiQu</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.1.1
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.6.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el: '#valine-comments',
      verify: false,
      notify: false,
      appId: 'wSTPHhQjMaXQJKPImj6BI7Qt-gzGzoHsz',
      appKey: 'pwRjDdVpxy5DcuwG8kMtytgS',
      placeholder: "Just go go",
      avatar: 'mm',
      meta: guest,
      pageSize: '10' || 10,
      visitor: true,
      lang: '' || 'zh-cn',
      path: location.pathname,
      recordIP: false,
      serverURLs: ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
